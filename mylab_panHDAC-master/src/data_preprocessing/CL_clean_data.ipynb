{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, MACCSkeys\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from confident_learning import MyConfidentLearning\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_excel(\"../../data/train_test_data/NoCL/20240207_pan_HDAC_train_test_data.xlsx\", sheet_name=\"train_dataset\")\n",
    "test_dataset = pd.read_excel(\"../../data/train_test_data/NoCL/20240207_pan_HDAC_train_test_data.xlsx\", sheet_name='test_dataset')\n",
    "validation_dataset = pd.read_excel(\"../../data/train_test_data/NoCL/20240207_pan_HDAC_train_test_data.xlsx\", sheet_name='validation_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115, 6) (239, 6) (240, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.shape, test_dataset.shape, validation_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOL_ID</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>IC50</th>\n",
       "      <th>IC50 of reference (vorinostat)</th>\n",
       "      <th>Bioactivity</th>\n",
       "      <th>Ref_DOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1162325</td>\n",
       "      <td>ONC(c1cnc(N(C[C@H]23)C[C@@H]2[C@H]3Nc2nc3ccccc...</td>\n",
       "      <td>490.4</td>\n",
       "      <td>60.2</td>\n",
       "      <td>inactive</td>\n",
       "      <td>10.1016/j.ejmech.2021.113799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136030779</td>\n",
       "      <td>C1=CC=C(C=C1)CN2C=C(N=N2)C3=CC(=CC=C3)C(=O)NO</td>\n",
       "      <td>58.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>active</td>\n",
       "      <td>10.1021/jm101605z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71520630</td>\n",
       "      <td>CC(C)C1=CC=C(C=C1)C(=O)NOCCCCCC(=O)NO</td>\n",
       "      <td>75.1</td>\n",
       "      <td>50.1</td>\n",
       "      <td>inactive</td>\n",
       "      <td>10.1021/acs.jmedchem.1c00821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>603695</td>\n",
       "      <td>COc1cc2ncnc(Nc3cc(C#C)ccc3)c2cc1OCCCCCC(NO)=O</td>\n",
       "      <td>15.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>active</td>\n",
       "      <td>10.1021/jm900125m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11723098</td>\n",
       "      <td>C1=CC=C(C=C1)CCN2C=CC(=N2)C3=CC=C(S3)C(=O)NO</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>inactive</td>\n",
       "      <td>10.1016/s0960-894x(02)00622-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MOL_ID                                             SMILES    IC50  \\\n",
       "0    1162325  ONC(c1cnc(N(C[C@H]23)C[C@@H]2[C@H]3Nc2nc3ccccc...   490.4   \n",
       "1  136030779      C1=CC=C(C=C1)CN2C=C(N=N2)C3=CC(=CC=C3)C(=O)NO    58.0   \n",
       "2   71520630              CC(C)C1=CC=C(C=C1)C(=O)NOCCCCCC(=O)NO    75.1   \n",
       "3     603695      COc1cc2ncnc(Nc3cc(C#C)ccc3)c2cc1OCCCCCC(NO)=O    15.0   \n",
       "4   11723098       C1=CC=C(C=C1)CCN2C=CC(=N2)C3=CC=C(S3)C(=O)NO  5000.0   \n",
       "\n",
       "   IC50 of reference (vorinostat) Bioactivity                        Ref_DOI  \n",
       "0                            60.2    inactive   10.1016/j.ejmech.2021.113799  \n",
       "1                           107.0      active              10.1021/jm101605z  \n",
       "2                            50.1    inactive   10.1021/acs.jmedchem.1c00821  \n",
       "3                            83.0      active              10.1021/jm900125m  \n",
       "4                           120.0    inactive  10.1016/s0960-894x(02)00622-4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MACCS\n",
    "from tqdm import tqdm\n",
    "\n",
    "def maccs_fpts(data):\n",
    "    Maccs_fpts = []\n",
    "    count = 0\n",
    "    with tqdm(total=len(data), desc='Progress') as pbar:\n",
    "        for i in data:\n",
    "            try:\n",
    "                mol = Chem.MolFromSmiles(i)\n",
    "                fpts = MACCSkeys.GenMACCSKeys(mol)\n",
    "            except:\n",
    "                print(\"An exception occurred with \" + str(count))\n",
    "                continue\n",
    "            mfpts = np.array(fpts)\n",
    "            Maccs_fpts.append(mfpts)\n",
    "            count += 1\n",
    "            pbar.update(1)  # Update the progress bar\n",
    "    return np.array(Maccs_fpts)\n",
    "\n",
    "#maccs\n",
    "def morgan_fpts(data):\n",
    "    Morgan_fpts = []\n",
    "    count = 0\n",
    "    with tqdm(total=len(data), desc='Progress') as pbar:\n",
    "        for i in data:\n",
    "            try:\n",
    "                mol = Chem.MolFromSmiles(i)\n",
    "                fpts = AllChem.GetMorganFingerprintAsBitVect(mol, 2, 1024)\n",
    "            except:\n",
    "                print(\"An exception occurred with \" + str(count))\n",
    "                continue\n",
    "            mfpts = np.array(fpts)\n",
    "            Morgan_fpts.append(mfpts)\n",
    "            count += 1\n",
    "            pbar.update(1)  # Update the progress bar\n",
    "    return np.array(Morgan_fpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/1115 [00:00<?, ?it/s][16:34:15] Conflicting single bond directions around double bond at index 26.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 17.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 26.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 16.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 25.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 18.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 27.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 15.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 21.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "Progress:  18%|█▊        | 204/1115 [00:00<00:00, 2038.90it/s][16:34:15] Conflicting single bond directions around double bond at index 18.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 27.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 17.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 26.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 21.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 6.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 15.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 6.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 15.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "Progress:  37%|███▋      | 408/1115 [00:00<00:00, 1872.16it/s][16:34:15] Conflicting single bond directions around double bond at index 22.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 22.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 25.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 16.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 25.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "Progress:  57%|█████▋    | 638/1115 [00:00<00:00, 2056.48it/s][16:34:15] Conflicting single bond directions around double bond at index 23.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 6.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 15.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 16.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 25.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 15.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 24.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 9.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 7.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 16.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "Progress:  76%|███████▌  | 846/1115 [00:00<00:00, 2005.46it/s][16:34:15] Conflicting single bond directions around double bond at index 15.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 12.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:15] Conflicting single bond directions around double bond at index 21.\n",
      "[16:34:15]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "Progress: 100%|██████████| 1115/1115 [00:00<00:00, 2023.64it/s]\n",
      "Progress:   0%|          | 0/239 [00:00<?, ?it/s][16:34:16] Conflicting single bond directions around double bond at index 17.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 26.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 21.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 27.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 7.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 18.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 27.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 21.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 21.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "Progress: 100%|██████████| 239/239 [00:00<00:00, 2339.52it/s]\n",
      "Progress:   0%|          | 0/240 [00:00<?, ?it/s][16:34:16] Conflicting single bond directions around double bond at index 8.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 17.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 26.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 7.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 16.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 7.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 16.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "[16:34:16] Conflicting single bond directions around double bond at index 19.\n",
      "[16:34:16]   BondStereo set to STEREONONE and single bond directions set to NONE.\n",
      "Progress: 100%|██████████| 240/240 [00:00<00:00, 2312.55it/s]\n"
     ]
    }
   ],
   "source": [
    "#X data\n",
    "X_Train = morgan_fpts(train_dataset['SMILES'])\n",
    "X_Test = morgan_fpts(test_dataset['SMILES'])\n",
    "X_Validation = morgan_fpts(validation_dataset['SMILES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1115, 1024) (239, 1024) (240, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(X_Train.shape, X_Test.shape, X_Validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n",
      "['inactive' 'active' 'inactive' 'active' 'inactive']\n",
      "['inactive' 'active' 'inactive' 'inactive' 'inactive']\n",
      "['active' 'inactive' 'active' 'inactive' 'inactive']\n",
      "Class encoded:\n",
      "['active', 'inactive']\n",
      "[0 1]\n",
      "Encoded data:\n",
      "[1 0 1 0 1]\n",
      "[1 0 1 1 1]\n",
      "[0 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#y data\n",
    "y_Train = np.array(train_dataset['Bioactivity'])\n",
    "y_Test = np.array(test_dataset['Bioactivity'])\n",
    "y_Validation = np.array(validation_dataset['Bioactivity'])\n",
    "\n",
    "#Original data\n",
    "print(\"Original data:\")\n",
    "print(y_Train[0:5])\n",
    "print(y_Test[0:5])\n",
    "print(y_Validation[0:5])\n",
    "\n",
    "#One-hot encoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_Train = label_encoder.fit_transform(y_Train)\n",
    "y_Test = label_encoder.transform(y_Test)\n",
    "y_Validation = label_encoder.transform(y_Validation)\n",
    "#Class encoded\n",
    "print(\"Class encoded:\")\n",
    "print(list(label_encoder.classes_))\n",
    "print(label_encoder.transform(label_encoder.classes_))\n",
    "print(\"Encoded data:\")\n",
    "print(y_Train[0:5])\n",
    "print(y_Test[0:5])\n",
    "print(y_Validation[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confident learning to remove label errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the models's accuracy with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = XGBClassifier(tree_method=\"gpu_hist\", enable_categorical=True)\n",
    "original_train_acc = cross_val_score(model, X_Train, y_Train, scoring='accuracy', cv=5)\n",
    "original_validation_acc = cross_val_score(model, X_Validation, y_Validation, scoring='accuracy', cv=5)\n",
    "original_test_acc = cross_val_score(model, X_Test, y_Test, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5551569506726457 0.5583333333333333 0.5023049645390072\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(original_train_acc), np.mean(original_validation_acc), np.mean(original_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1 - Method 2: Estimate the label errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and pruning label errors using vanilla CL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Getting out of sample probality\n",
      "[-] Finished getting out of sample probality with shape: (1115, 2)\n",
      "[+] Getting out of sample probality\n",
      "[-] Finished getting out of sample probality with shape: (240, 2)\n",
      "[+] Getting out of sample probality\n",
      "[-] Finished getting out of sample probality with shape: (239, 2)\n"
     ]
    }
   ],
   "source": [
    "train_cl = MyConfidentLearning(X=X_Train, y=y_Train)\n",
    "train_pred_probs = train_cl.get_out_of_sample_proba()\n",
    "\n",
    "validation_cl = MyConfidentLearning(X=X_Validation, y=y_Validation)\n",
    "validation_pred_probs = validation_cl.get_out_of_sample_proba()\n",
    "\n",
    "test_cl = MyConfidentLearning(X=X_Test, y=y_Test)\n",
    "test_pred_probs = test_cl.get_out_of_sample_proba()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Class threshold__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Computing thresholds\n",
      "[-] Finished compute thresholds: [0.35634137 0.65191514]\n",
      "[+] Computing thresholds\n",
      "[-] Finished compute thresholds: [0.40895423 0.6395467 ]\n",
      "[+] Computing thresholds\n",
      "[-] Finished compute thresholds: [0.30361629 0.62587541]\n"
     ]
    }
   ],
   "source": [
    "# should be a numpy array of length 5\n",
    "train_thresholds = train_cl.compute_class_thresholds()\n",
    "validation_thresholds = validation_cl.compute_class_thresholds()\n",
    "test_thresholds = test_cl.compute_class_thresholds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Confident joint__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Computing confident joint\n",
      "[-] Finished compute confident joint:\n",
      "[[179 223]\n",
      " [288 418]]\n",
      "[+] Computing confident joint\n",
      "[-] Finished compute confident joint:\n",
      "[[42 49]\n",
      " [54 86]]\n",
      "[+] Computing confident joint\n",
      "[-] Finished compute confident joint:\n",
      "[[33 49]\n",
      " [67 90]]\n"
     ]
    }
   ],
   "source": [
    "C_train = train_cl.compute_confident_joint()\n",
    "C_validation = validation_cl.compute_confident_joint()\n",
    "C_test = test_cl.compute_confident_joint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Estimate label errors__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_noise_rate(C, no_of_samples):\n",
    "    num_label_issues = np.sum(C - np.diag(np.diag(C)))\n",
    "    print(f\"Number of label issues: {num_label_issues}\")\n",
    "    print('Estimated noise rate: {:.1f}%'.format(100*num_label_issues / no_of_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:\n",
      "Number of label issues: 511\n",
      "Estimated noise rate: 45.8%\n",
      "Validation dataset:\n",
      "Number of label issues: 103\n",
      "Estimated noise rate: 42.9%\n",
      "Test dataset\n",
      "Number of label issues: 116\n",
      "Estimated noise rate: 48.5%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset:\")\n",
    "caculate_noise_rate(C_train, train_cl.X.shape[0])\n",
    "print(\"Validation dataset:\")\n",
    "caculate_noise_rate(C_validation, validation_cl.X.shape[0])\n",
    "print(\"Test dataset\")\n",
    "caculate_noise_rate(C_test, test_cl.X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pruning label issues__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Finding labels issue indeces:\n",
      "Issue indices: 511\n",
      "[+] Finding labels issue indeces:\n",
      "Issue indices: 103\n",
      "[+] Finding labels issue indeces:\n",
      "Issue indices: 116\n"
     ]
    }
   ],
   "source": [
    "train_issue_indices = train_cl.find_label_issues()\n",
    "validation_issue_indices = validation_cl.find_label_issues()\n",
    "test_issue_indices = test_cl.find_label_issues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the label errors found by Confident Learning\n",
    "clean_X_train = np.delete(X_Train, train_issue_indices, axis=0) \n",
    "clean_y_train = np.delete(y_Train, train_issue_indices)\n",
    "clean_train_pred_probs = np.delete(train_cl.pred_probs, train_issue_indices, axis=0)\n",
    "\n",
    "clean_X_validation = np.delete(X_Validation, validation_issue_indices, axis=0) \n",
    "clean_y_validation = np.delete(y_Validation, validation_issue_indices)\n",
    "clean_validation_pred_probs = np.delete(validation_cl.pred_probs, validation_issue_indices, axis=0)\n",
    "\n",
    "clean_X_test = np.delete(X_Test, test_issue_indices, axis=0) \n",
    "clean_y_test = np.delete(y_Test, test_issue_indices)\n",
    "clean_test_pred_probs = np.delete(test_cl.pred_probs, test_issue_indices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train = train_dataset.drop(train_issue_indices)\n",
    "clean_val = validation_dataset.drop(validation_issue_indices)\n",
    "clean_test = test_dataset.drop(test_issue_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Check Confident joint again__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_confident_joint(pred_probs: np.ndarray, thresholds: np.ndarray, labels: np.ndarray) -> np.ndarray:\n",
    "    print(\"[+] Computing confident joint\")\n",
    "    n_examples, n_classes = pred_probs.shape\n",
    "    confident_joint = np.zeros((n_classes, n_classes), dtype=np.int64)\n",
    "    for data_idx in range(n_examples):\n",
    "        i = labels[data_idx]    #y_noise\n",
    "        j = None                #y_true -> to find\n",
    "        #Lưu ý điểm mình bị sai: vị trí của chúng không ứng với label\n",
    "        p_j = -1\n",
    "        for candidate_j in range(n_classes):\n",
    "            p = pred_probs[data_idx, candidate_j]\n",
    "            if p >= thresholds[candidate_j] and p > p_j:\n",
    "                j = candidate_j\n",
    "                p_j = p\n",
    "        if j is not None:\n",
    "            confident_joint[i][j] += 1\n",
    "    print(\"[-] Finished compute confident joint:\")\n",
    "    print(confident_joint)\n",
    "    return confident_joint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset:\n",
      "[+] Computing confident joint\n",
      "[-] Finished compute confident joint:\n",
      "[[179   0]\n",
      " [  0 418]]\n",
      "Validation dataset\n",
      "[+] Computing confident joint\n",
      "[-] Finished compute confident joint:\n",
      "[[42  0]\n",
      " [ 0 86]]\n",
      "Test dataset\n",
      "[+] Computing confident joint\n",
      "[-] Finished compute confident joint:\n",
      "[[33  0]\n",
      " [ 0 90]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset:\")\n",
    "clean_C_train = compute_confident_joint(pred_probs=clean_train_pred_probs, thresholds=train_thresholds, labels=clean_y_train)\n",
    "\n",
    "print(\"Validation dataset\")\n",
    "clean_C_validation = compute_confident_joint(pred_probs=clean_validation_pred_probs, thresholds=validation_thresholds, labels=clean_y_validation)\n",
    "\n",
    "print(\"Test dataset\")\n",
    "clean_C_test = compute_confident_joint(pred_probs=clean_test_pred_probs, thresholds=test_thresholds, labels=clean_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing models with clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8824380165289256 0.8687830687830687 0.8220000000000001\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = XGBClassifier(tree_method=\"gpu_hist\", enable_categorical=True)\n",
    "clean_train_acc = cross_val_score(model, clean_X_train, clean_y_train, scoring='accuracy', cv=5)\n",
    "clean_validation_acc = cross_val_score(model, clean_X_validation, clean_y_validation, scoring='accuracy', cv=5)\n",
    "clean_test_acc = cross_val_score(model, clean_X_test, clean_y_test, scoring='accuracy', cv=5)\n",
    "\n",
    "print(np.mean(clean_train_acc), np.mean(clean_validation_acc), np.mean(clean_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def show_activity_distribution(dataset):\n",
    "    #Rows for specific labels\n",
    "    active_rows = dataset.loc[dataset[\"Bioactivity\"] == \"active\"]\n",
    "    inactive_rows = dataset.loc[dataset[\"Bioactivity\"] == \"inactive\"]\n",
    "    dataset_length = len(dataset)\n",
    "    print(f\"Total dataset: {dataset_length}\")\n",
    "    table = [['', 'Active', 'Inactive'], \n",
    "            ['Number', len(active_rows), len(inactive_rows)],\n",
    "            ['Percentage (%)', len(active_rows)/dataset_length, len(inactive_rows)/dataset_length]]\n",
    "    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset: 604\n",
      "╒════════════════╤════════════╤════════════╕\n",
      "│                │     Active │   Inactive │\n",
      "╞════════════════╪════════════╪════════════╡\n",
      "│ Number         │ 182        │ 422        │\n",
      "├────────────────┼────────────┼────────────┤\n",
      "│ Percentage (%) │   0.301325 │   0.698675 │\n",
      "╘════════════════╧════════════╧════════════╛\n",
      "Total dataset: 123\n",
      "╒════════════════╤═══════════╤════════════╕\n",
      "│                │    Active │   Inactive │\n",
      "╞════════════════╪═══════════╪════════════╡\n",
      "│ Number         │ 33        │  90        │\n",
      "├────────────────┼───────────┼────────────┤\n",
      "│ Percentage (%) │  0.268293 │   0.731707 │\n",
      "╘════════════════╧═══════════╧════════════╛\n",
      "Total dataset: 137\n",
      "╒════════════════╤═══════════╤════════════╕\n",
      "│                │    Active │   Inactive │\n",
      "╞════════════════╪═══════════╪════════════╡\n",
      "│ Number         │ 46        │  91        │\n",
      "├────────────────┼───────────┼────────────┤\n",
      "│ Percentage (%) │  0.335766 │   0.664234 │\n",
      "╘════════════════╧═══════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "show_activity_distribution(clean_train)\n",
    "show_activity_distribution(clean_test)\n",
    "show_activity_distribution(clean_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"../../data/train_test_data/CL_then_balance/20240216_clean_data_approach1_method2.xlsx\") as writer:\n",
    "    # use to_excel function and specify the sheet_name and index \n",
    "    # to store the dataframe in specified sheet\n",
    "    clean_train.to_excel(writer, sheet_name=\"train_dataset\", index=False)\n",
    "    clean_val.to_excel(writer, sheet_name=\"validation_dataset\", index=False)\n",
    "    clean_test.to_excel(writer, sheet_name=\"test_dataset\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cleanlab to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use clean lab to find and pruning label errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleanlab\n",
    "from cleanlab.classification import CleanLearning\n",
    "from cleanlab.benchmarking import noise_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_train = cleanlab.classification.CleanLearning(clf=XGBClassifier(), seed=42)\n",
    "_ = cl_train.fit(X_Train, y_Train)\n",
    "\n",
    "cl_test = cleanlab.classification.CleanLearning(clf=XGBClassifier(), seed=42)\n",
    "_ = cl_test.fit(X_Test, y_Test)\n",
    "\n",
    "cl_val = cleanlab.classification.CleanLearning(clf=XGBClassifier(), seed=42)\n",
    "_ = cl_val.fit(X_Validation, y_Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_issues_df = cl_train.get_label_issues()\n",
    "print(len(train_label_issues_df))\n",
    "train_label_issues_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting issue labels\n",
    "train_label_issue = np.array(cl_train.get_label_issues()[\"is_label_issue\"].values)\n",
    "test_label_issue = np.array(cl_test.get_label_issues()[\"is_label_issue\"].values)\n",
    "validation_label_issue = np.array(cl_val.get_label_issues()[\"is_label_issue\"].values)\n",
    "#Get the issue index\n",
    "train_issue_idx = (train_label_issue > 0).nonzero()[0]\n",
    "test_issue_idx = (test_label_issue > 0).nonzero()[0]\n",
    "valiadation_issue_idx = (validation_label_issue > 0).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning label errors\n",
    "clean_X_train = np.delete(X_Train, train_issue_idx, axis=0) \n",
    "clean_y_train = np.delete(y_Train, train_issue_idx)\n",
    "\n",
    "clean_X_validation = np.delete(X_Validation, valiadation_issue_idx, axis=0) \n",
    "clean_y_validation = np.delete(y_Validation, valiadation_issue_idx)\n",
    "\n",
    "clean_X_test = np.delete(X_Test, test_issue_idx, axis=0) \n",
    "clean_y_test = np.delete(y_Test, test_issue_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pruning label errors\n",
    "clean_train = train_dataset.drop(train_issue_idx)\n",
    "clean_val = validation_dataset.drop(valiadation_issue_idx)\n",
    "clean_test = test_dataset.drop(test_issue_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the models' accuracy on clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model = XGBClassifier(tree_method=\"gpu_hist\", enable_categorical=True)\n",
    "clean_train_acc = cross_val_score(model, clean_X_train, clean_y_train, scoring='accuracy', cv=5)\n",
    "clean_validation_acc = cross_val_score(model, clean_X_validation, clean_y_validation, scoring='accuracy', cv=5)\n",
    "clean_test_acc = cross_val_score(model, clean_X_test, clean_y_test, scoring='accuracy', cv=5)\n",
    "print(np.mean(clean_train_acc), np.mean(clean_validation_acc), np.mean(clean_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def show_activity_distribution(dataset):\n",
    "    #Rows for specific labels\n",
    "    active_rows = dataset.loc[dataset[\"Bioactivity\"] == \"active\"]\n",
    "    inactive_rows = dataset.loc[dataset[\"Bioactivity\"] == \"inactive\"]\n",
    "    dataset_length = len(dataset)\n",
    "    print(f\"Total dataset: {dataset_length}\")\n",
    "    table = [['', 'Active', 'Inactive'], \n",
    "            ['Number', len(active_rows), len(inactive_rows)],\n",
    "            ['Percentage (%)', len(active_rows)/dataset_length, len(inactive_rows)/dataset_length]]\n",
    "    print(tabulate(table, headers='firstrow', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_activity_distribution(clean_train)\n",
    "show_activity_distribution(clean_test)\n",
    "show_activity_distribution(clean_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(\"../../data/train_test_data/CL/20240207_clean_data_with_cleanlab.xlsx\") as writer:\n",
    "    # use to_excel function and specify the sheet_name and index \n",
    "    # to store the dataframe in specified sheet\n",
    "    clean_train.to_excel(writer, sheet_name=\"train_dataset\", index=False)\n",
    "    clean_val.to_excel(writer, sheet_name=\"validation_dataset\", index=False)\n",
    "    clean_test.to_excel(writer, sheet_name=\"test_dataset\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
