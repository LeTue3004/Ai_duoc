{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notification__: The raw data from PubChem database have many errors and duplicates, therefore, this file perform the cleaning it.\n",
    "- Use the my-rdkit-env environment\n",
    "- The data that we used after preprocessing is availible in this link: https://drive.google.com/file/d/1YIhBD51oWA0s3p-egIHepNb3iZZbXqb1/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "import os\n",
    "import psycopg2\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "\n",
    "#MACCS\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Descriptors import ExactMolWt\n",
    "from rdkit import RDLogger  \n",
    "import sys\n",
    "sys.path.append(\"/home/mylab-pharma/Code/tuele/pan_HDAC/mylab_panHDAC-master/src/common\")\n",
    "from pharmacy_common import PharmacyCommon\n",
    "#class to encode smiles\n",
    "common = PharmacyCommon()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text data converted to CSV successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Step 1: Read the text data\n",
    "with open('/home/mylab-pharma/Code/tuele/pan_HDAC/mylab_panHDAC-master/data/screening_data/enamine_hits.txt', 'r') as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "# Step 2: Parse the text data\n",
    "rows = text_data.split('\\n')  # Split text into rows based on newlines\n",
    "data = [row.split('\\t') for row in rows]  # Split rows into columns based on tab delimiter\n",
    "\n",
    "# Step 3: Create a CSV file\n",
    "with open('/home/mylab-pharma/Code/tuele/pan_HDAC/mylab_panHDAC-master/data/screening_data/enamine_hits.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Step 4: Write data to the CSV file\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"Text data converted to CSV successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the train - test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_path = \"../../data/train_test_data/NoCL/20240321_pan_HDAC_train_test_data.xlsx\"\n",
    "train_dataset = pd.read_excel(train_test_path, sheet_name='train_dataset')\n",
    "test_dataset = pd.read_excel(train_test_path, sheet_name='test_dataset')\n",
    "validation_dataset = pd.read_excel(train_test_path, sheet_name='validation_dataset')\n",
    "\n",
    "train_test_dataset = pd.concat([train_dataset, test_dataset, validation_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1528 327 328 2183\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(test_dataset), len(validation_dataset), len(train_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Bioactivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>415897</td>\n",
       "      <td>CC(Nc1ccc(CN(CCC=C2CCC(NO)=O)C2=O)cc1)=O</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1589183</td>\n",
       "      <td>COc(cc(/C=C/C(Nc(cccc1)c1N)=O)cc1)c1OCC(Nc(cc1...</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1161066</td>\n",
       "      <td>CC[C@H](C)[C@@H](C(N(Cc1c(C2)ccc(OCC(NO)=O)c1)...</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2100074</td>\n",
       "      <td>CC(c1ccccc1)Nc1ncnc2c1cc(-c1ccc(CN3CCN(CCOCCCC...</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>386804</td>\n",
       "      <td>CC(C)SC(SCC(c1ccc(C)cc1)=O)=S</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Code                                             SMILES Bioactivity\n",
       "0   415897           CC(Nc1ccc(CN(CCC=C2CCC(NO)=O)C2=O)cc1)=O    inactive\n",
       "1  1589183  COc(cc(/C=C/C(Nc(cccc1)c1N)=O)cc1)c1OCC(Nc(cc1...    inactive\n",
       "2  1161066  CC[C@H](C)[C@@H](C(N(Cc1c(C2)ccc(OCC(NO)=O)c1)...      active\n",
       "3  2100074  CC(c1ccccc1)Nc1ncnc2c1cc(-c1ccc(CN3CCN(CCOCCCC...    inactive\n",
       "4   386804                      CC(C)SC(SCC(c1ccc(C)cc1)=O)=S    inactive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking and insert data into the preprocessing table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_error_fpts(check_dataset, smiles_column):\n",
    "    \"\"\"\n",
    "    Checks for errors in MACCS fingerprint calculation.\n",
    "\n",
    "    Args:\n",
    "        check_dataset (pd.DataFrame): The dataset to be checked.\n",
    "        smiles_column (str): The name of the SMILES column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The rows with errors in MACCS fingerprint calculation.\n",
    "    \"\"\"\n",
    "    result_df = pd.DataFrame(columns=check_dataset.columns)\n",
    "    for index, row in check_dataset.iterrows():\n",
    "        current_smiles = str(row[smiles_column]).strip()\n",
    "        if current_smiles is not None and len(current_smiles) > 0:\n",
    "            try:\n",
    "                RDLogger.DisableLog('rdApp.info')\n",
    "                mol = Chem.MolFromSmiles(current_smiles)\n",
    "                if mol is not None:\n",
    "                    result_df = pd.concat([result_df, row.to_frame().T], axis=0)  # Concatenate the current row                \n",
    "                else:\n",
    "                    logging.info(\"Could not interpret \" + current_smiles + \" to mol object!\")\n",
    "            except Exception as e:\n",
    "                logging.error(\"An exception occurred at row \" + str(index) + \": \" + str(e))\n",
    "                continue\n",
    "    return result_df\n",
    "\n",
    "def preprocess_dataset(working_dataset, train_test_dataset):\n",
    "    \"\"\"\n",
    "    Preprocesses the dataset by removing duplicate SMILES and rows with errors in MACCS fingerprint calculation.\n",
    "\n",
    "    Args:\n",
    "        working_dataset (pd.DataFrame): The dataset to be preprocessed.\n",
    "        train_test_dataset (pd.DataFrame): The training/testing dataset.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The preprocessed dataset.\n",
    "    \"\"\"\n",
    "    #Filter\n",
    "    logging.info(\"[+] Working dataset: \" + str(len(working_dataset)))\n",
    "    #Check for error smiles while encoding\n",
    "    working_dataset = check_error_fpts(working_dataset, 'SMILES')\n",
    "    #Resert index\n",
    "    working_dataset.reset_index(drop=True, inplace=True) \n",
    "    # Get the duplicate SMILES from the training/testing dataset.\n",
    "    duplicate_smiles = working_dataset[working_dataset['SMILES'].isin(train_test_dataset['SMILES'])]\n",
    "    logging.info(\"[+] Duplicate with the train-test data: \" + str(len(duplicate_smiles)))\n",
    "    # Get the indices of duplicate smiles in test_working_dataset\n",
    "    duplicate_indices = duplicate_smiles.index\n",
    "    # Remove rows with duplicate SMILES from test_working_dataset\n",
    "    working_dataset.drop(index=duplicate_indices, inplace=True)\n",
    "    #Ending report\n",
    "    logging.info(\"[+] Ending preprocessing: \" + str(len(working_dataset)))\n",
    "    return working_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Screening data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O=C1CCON1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCC(=O)NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCC(=O)NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CON(C)C(C)=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ON1C(=O)CCC1=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CC1(C)CONC1=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CC(C)(C)C(=O)NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CCC(=O)N(C)OC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CCC(N)C(=O)NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COCONC(C)=O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SMILES\n",
       "0        O=C1CCON1\n",
       "1        CCC(=O)NO\n",
       "2        NCC(=O)NO\n",
       "3     CON(C)C(C)=O\n",
       "4   ON1C(=O)CCC1=O\n",
       "5    CC1(C)CONC1=O\n",
       "6  CC(C)(C)C(=O)NO\n",
       "7    CCC(=O)N(C)OC\n",
       "8    CCC(N)C(=O)NO\n",
       "9      COCONC(C)=O"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screening_data_path = \"../../data/screening_data/all_screen_data.xlsx\"\n",
    "screening_data = pd.read_excel(screening_data_path, sheet_name='final_screen_data')\n",
    "screening_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_working_dataset = screening_data.iloc[:10,:]\n",
    "error_dataset = {\n",
    "    # test_working_dataset.columns[0]: [6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "    test_working_dataset.columns[0]: ['O=C(NO)c1cnc(NC2(c3ccc(C(F)(F)F)c(F)c3)CC2)nc1', '', '4453', 'hellow rodl', 'Cc1cn(C)nc1CN1CCC(c2ccc(C(=O)Nc3ccccc3N)cc2)CC1', 'qwe', '####@@qds', None, ' ', '']\n",
    "}\n",
    "error_dataset = pd.DataFrame(error_dataset)\n",
    "test_working_dataset = pd.concat([test_working_dataset, error_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:59:46] SMILES Parse Error: syntax error while parsing: 4453\n",
      "[09:59:46] SMILES Parse Error: Failed parsing SMILES '4453' for input: '4453'\n",
      "[09:59:46] SMILES Parse Error: syntax error while parsing: hellow\n",
      "[09:59:46] SMILES Parse Error: Failed parsing SMILES 'hellow' for input: 'hellow'\n",
      "[09:59:46] SMILES Parse Error: syntax error while parsing: qwe\n",
      "[09:59:46] SMILES Parse Error: Failed parsing SMILES 'qwe' for input: 'qwe'\n",
      "[09:59:46] SMILES Parse Error: syntax error while parsing: ####@@qds\n",
      "[09:59:46] SMILES Parse Error: Failed parsing SMILES '####@@qds' for input: '####@@qds'\n",
      "[09:59:46] SMILES Parse Error: syntax error while parsing: None\n",
      "[09:59:46] SMILES Parse Error: Failed parsing SMILES 'None' for input: 'None'\n"
     ]
    }
   ],
   "source": [
    "test_working_dataset = preprocess_dataset(working_dataset=test_working_dataset, train_test_dataset=train_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542869\n"
     ]
    }
   ],
   "source": [
    "print(len(screening_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/542869 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  89%|████████▉ | 483427/542869 [02:56<00:21, 2703.03it/s][10:02:47] WARNING: not removing hydrogen atom without neighbors\n",
      "Progress:  91%|█████████ | 495167/542869 [03:01<00:17, 2751.81it/s][10:02:51] WARNING: not removing hydrogen atom without neighbors\n",
      "Progress:  94%|█████████▍| 512118/542869 [03:06<00:09, 3077.73it/s][10:02:56] WARNING: not removing hydrogen atom without neighbors\n",
      "Progress:  96%|█████████▌| 518980/542869 [03:09<00:08, 2749.47it/s][10:02:59] WARNING: not removing hydrogen atom without neighbors\n",
      "Progress:  99%|█████████▉| 538862/542869 [03:16<00:01, 2622.21it/s][10:03:06] WARNING: not removing hydrogen atom without neighbors\n",
      "Progress: 100%|█████████▉| 542421/542869 [03:17<00:00, 2843.17it/s][10:03:08] WARNING: not removing hydrogen atom without neighbors\n",
      "Progress: 100%|██████████| 542869/542869 [03:17<00:00, 2743.23it/s]\n"
     ]
    }
   ],
   "source": [
    "encoding_screen_data = common.gen_ecfp4_fpts(screening_data[\"SMILES\"],bits= 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542869\n"
     ]
    }
   ],
   "source": [
    "print(len(encoding_screen_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diversity-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
